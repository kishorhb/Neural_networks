# Neural_networks
A neural network can be understood as a network of hidden layers, an input layer and an output layer that tries to mimic the working of a human brain.

The hidden layers can be visualized as an abstract representation of the input data itself. These layers help the neural network understand various features of the data with the help of its own internal logic.

These neural networks are non-interpretable models. Non-interpretable models are those which can’t be interpreted or understood even if we observe the hidden layers. This is because the neural networks have an internal logic working on its own, that can’t be comprehended by us.

We can just see then as a vector of numerical values. Since the output of a neural network is a numerical vector, we need to have an explicit output layer that bridges the gap between the actual data and the representation of the data by the network.

An output layer can be understood as a translator that helps us to understand the logic of the network and convert the target values.

A theorem named ‘Universal approximation theorem’ tells that a feedforward network that contains one hidden layer can be used to represent any function.

This means there is no limit on the functioning of a neural network that contains one hidden layer. But in real life situations, a neural network with one hidden layer can’t be used well.

A neural network is a mathematical model that helps in processing information. It is not a set of lines of code, but a model or a system that helps process the inputs/information and gives result.

The information is processed in the simplest form over basic elements known as ‘neurons’. Neurons are connected and help exchange signals/information between them with the help of connection links.

This connection links between neurons could be strong or weak, and this strength of the connection links determines the method in which information is processed.

Every neuron has an internal state which can be determined by the incoming connections from other neurons.

Every neuron has an activation function which is calculated on its state, and this helps determine its output signal.

A neural network can be understood as a computational graph of mathematical operations.

Two main characteristics of a neural network −

Architecture
Learning

Architecture
It tells about the connection type: whether it is feedforward, recurrent, multi-layered, convolutional, or single layered. It also tells about the number of layers and the number of neurons in every layer.

Learning
It tells about the method in which the neural network is trained. A common way to train a neural network is to use gradient descent and backpropagation.
